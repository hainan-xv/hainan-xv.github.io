<head>
<style>
p    {max-width:95%; word-wrap:break-word; line-height: 120%;}
li	{max-width:98%; word-wrap:break-word;}
</style>
</head>

<font face="Arial">

<title> Hainan Xu | Speech Recognition Researcher </title>

<table align="left" cols="3" cellspacing="10" cellpadding="20" width="100%">
<tbody><tr><td align="left" width="130">
	<a href="./pic.jpg" target="_blank">
    <img src="pic.jpg" align="bottom" height="300" width="300" border="2" alt="My
	Image" bcolor="white"></a>
</td><td>
    <font size="6"><b>Hainan Xu (许海南)</b></font> 
	<br><br>

    Senior Applied Scientist at NVIDIA <br> <br>
    E-mail: see <a href="https://docs.google.com/document/d/1sFa2zyoU9p3hJfZDUDFh41PVhPWh5nIRhCxVJs0se_M/edit?usp=sharing" target="_blank">my resume</a> <br>
    <br>
    <a href="hainan_thesis.pdf" target="_blank">Thesis</a> <br>
    <a href="https://scholar.google.com/citations?user=LUpv8foAAAAJ&hl=en" target="_blank">Google Scholar</a> <br>
    <a href="https://www.linkedin.com/in/hainanxv" target="_blank">LinkedIn</a> <br>
    <a href="https://www.youtube.com/channel/UC8c_aOob3ck4dIRh9FGwA9Q/videos" target="_blank">YouTube Channel</a> <br>
    <a href="https://www.instagram.com/hainan_ang_xu/" target="_blank">Instagram</a> <br>
    <a href="https://space.bilibili.com/582308421?spm_id_from=333.1007.0.0" target="_blank">B站</a> <br>

    </font></b></td>
</font></td>


<font size="2">
<table border="0" cellpadding="2" width="98%" bgcolor="#eee9e9" id="biography">
<tbody><tr>
<td align="LEFT"><b><font face="Arial,Helvetica" color="#000000" size="4">Biography
</tr>
</tbody></table>

<font size="3">
<ul style="list-style-type:none">

<li>
<p>
I am currently working in NVIDIA's <a href="https://https://github.com/NVIDIA/NeMo" target="_blank">NeMo</a> Team, supervised by <a href="https://www.linkedin.com/in/boris-ginsburg-2249545" target="_blank">Boris Ginsburg</a>.
Before joining NVIDIA,
I worked in Google's Speech Team under <a href="https://sites.google.com/site/thebhuv/" target="_blank">Bhuvana Ramabhadran</a> from September 2019
to October 2021, after getting my Ph.D. degree in Computer Science from the <a href="http://www.jhu.edu/"
target="_blank">Johns Hopkins University</a>,
working in the <a href="http://www.clsp.jhu.edu/" target="_blank">Center for Language and Speech Processing (CLSP)</a> under
former JHU Prof. <a
href="http://www.danielpovey.com" target="_blank">Daniel Povey</a> and Prof.
<a href="http://www.clsp.jhu.edu/people/faculty/sanjeev/" target="_blank">Sanjeev Khudanpur</a>.
</p>
</li>

<li>
<p>
I received my B.S. in Software Engineering in 2012 from <a
href="http://www.se.sjtu.edu.cn/" target="_blank">School of Software
Engineering </a> at <a href="http://en.sjtu.edu.cn/" target="_blank">Shanghai
Jiaotong University</a> in Shanghai, China. From 2012 to 2013,  I worked with
Professor <a href="http://mi.eng.cam.ac.uk/~ky219/" target="_blank">
Kai Yu</a> in <a href="http://speechlab.sjtu.edu.cn/"
target="_blank">SJTU Speech Lab</a>.
</p>
</li>

</ul>



<font size="2">
<table border="0" cellpadding="2" width="98%" bgcolor="#eee9e9" id="education">
<tbody><tr>
<td align="LEFT"><b><font face="Arial,Helvetica" color="#000000" size="4">Education</font></b></td>
</tr>
</tbody></table>

<font size="3">
<ul>
<li><b>Ph.D. </b> in Computer Science
(Sept 2013 - Sept 2019)  <br>
<a href="http://www.cs.jhu.edu" target="_blank">Department of Computer Science</a><br>
<a href="http://www.jhu.edu/" target="_blank">Johns Hopkins University</a>, MD, USA<br>
</li>
<br>

<li><b>B.S.</b> in Software Engineering 
(Sept 2008 - Jun 2012) <br>
<a href="http://www.se.sjtu.edu.cn/" target="_blank">School of Software Engineering</a><br>
<a href="http://en.sjtu.edu.cn/" target="_blank">Shanghai Jiaotong
University</a>, Shanghai, China<br>
</li>

</ul>


<font size="2">
<table border="0" cellpadding="2" width="98%" bgcolor="#eee9e9" id="experience">
<tbody><tr>
<td align="LEFT"><b><font face="Arial,Helvetica" color="#000000" size="4">Work Experience</font></b></td>
</tr>
</tbody></table>

<font size="3">
<ul>
<li><b>Senior Applied Scientist</b> <br>
NVIDIA
(Nov 2021 - Present)  <br>
I do research in the <a href="https://https://github.com/NVIDIA/NeMo" target="_blank">NeMo</a> team. My supervisor is  <a href="https://www.linkedin.com/in/boris-ginsburg-2249545" target="_blank">Boris Ginsburg</a>.
</li>
</ul>

<font size="3">
<ul>
<li><b>Software Engineer</b> <br>
Google Inc, New York City, NY 
(Sept 2019 - Oct 2021)  <br>
I worked in the speech team, doing research to help Google's speech recognition models, supervised by  <a href="https://sites.google.com/site/thebhuv/" target="_blank">Bhuvana Ramabhadran</a>.
</li>
</ul>

<font size="3">
<ul>
<li><b>Research Intern</b> <br>
Spoken Communications, Seattle, WA
(May 2017 - Aug 2017)  <br>
I <a href="https://developers.googleblog.com/2017/08/kaldi-now-offers-tensorflow-integration.html" target="_blank">incorporated</a>
support for TensorFlow-based language model rescoring in Kaldi.
</li>
</ul>

<font size="3">
<ul>
<li><b>Research Intern</b> <br>
Google Inc., New York City, NY
(May 2015 - Aug 2015)  <br>
I worked with <a href="http://research.google.com/pubs/author130.html" target="_blank">Cyril Allauzen</a> and 
<a href="http://research.google.com/pubs/author125.html" target="_blank">Michael Riley</a>
on improving contextual language modeling for Google speech recognition, using finite state methods implemented with
<a href="http://www.openfst.org/twiki/bin/view/FST/WebHome" target="_blank">OpenFst</a>
and
<a href="http://www.openfst.org/twiki/bin/view/GRM/NGramLibrary" target="_blank">OpenGrm</a>.
</li>
</ul>

<font size="3">
<ul>
<li><b>Research Assistant</b> <br>
<a href="http://www.clsp.jhu.edu/" target="_blank">Center for Language and Speech Processing</a>
(Sept 2013 - Sept 2019)  <br>
I worked with Dan Povey and Sanjeev Khudanpur on speech recognition, and contributed to the Kaldi project.
</ul>
</li>

<font size="3">
<ul>
<li><b>Research Assistant</b> <br>
<a href="http://speechlab.sjtu.edu.cn/" target="_blank">Speech Lab at Shanghai Jiaotong University</a>
(July 2012 - July 2013)  <br>
I worked with Kai Yu on speech recognition, speech synthesis and human-computer iteractions. 
</ul>
</li>
<br>

<font size="2">
<table border="0" cellpadding="2" width="98%" bgcolor="#eee9e9" id="experience">
<tbody><tr>
<td align="LEFT"><b><font face="Arial,Helvetica" color="#000000" size="4">Teaching Experience</font></b></td>
</tr>
</tbody></table>

<font size="3">
<ul>
<li><b>Teaching Assistant</b> <br>
Johns Hopkins University
(Spring Semester 2017)  <br>
Course: Information Extraction</a>
<br>
Instructor: <a href="http://www.clsp.jhu.edu/faculty-pages/sanjeev/" target="_blank">Sanjeev Khudanpur</a>
</li>
</ul>

<font size="3">
<ul>
<li><b>Teaching Assistant</b> <br>
Johns Hopkins University
(Spring Semester 2016)  <br>
Course: Information Theory</a>
<br>
Instructor: <a href="http://www.clsp.jhu.edu/faculty-pages/sanjeev/" target="_blank">Sanjeev Khudanpur</a>
</li>
</ul>

<font size="3">
<ul>
<li><b>Teaching Assistant</b> <br>
Johns Hopkins University
(Fall Semester 2015)  <br>
Course: <a href="http://www.cs475.org/fall2015/" target="_blank">Introduction to Machine Learning</a>
<br>
Instructor: <a href="https://www.cs.jhu.edu/faculty/ilya-shpitser-3/" target="_blank">Ilya Shpitser</a>
</li>
</ul>


<font size="2">
<table border="0" cellpadding="2" width="98%" bgcolor="#eee9e9" id="publications">
<tbody><tr>
<td align="LEFT"><b><font face="Arial,Helvetica" color="#000000" size="4">Selected Publications</font></b></td>
</tr>
</tbody></table>
<font size="3">
(slightly outdated. See my <a href="https://scholar.google.com/citations?user=LUpv8foAAAAJ&hl=en" target="_blank">Google Scholar page</a> for a more complete list.)

<ul>

<li>Shuoyang Ding, <b>Hainan Xu</b>, Philipp Koehn <br>
<a href="https://arxiv.org/abs/1906.10282" target="_blank">Saliency-driven Word Alignment Interpretation for Neural Machine Translation</a><br>
(<b>WMT 2019</b>)
</li>
<br>

<li><b>Hainan Xu</b>, Shuoyang Ding, Shinji Watanabe <br>
<a href="https://arxiv.org/abs/1811.04284" target="_blank">Improving End-to-end Speech Recognition with Pronunciation-assisted Sub-word Modeling</a><br>
(<b>ICASSP 2019</b>)
</li>
<br>

<li><b>Hainan Xu</b>, Tongfei Chen, Dongji Gao, Yiming Wang, Ke Li, Nagendra Goel, Yishay Carmiel, Daniel Povey, Sanjeev Khudanpur <br>
<a href="pruned-rnnlm-lattice.pdf" target="_blank">A Pruned Rnnlm Lattice-rescoring Algorithm for Automatic Speech Recognition</a><br>
(<b>ICASSP 2018</b>)
</li>
<br>

<li><b>Hainan Xu</b>, Ke Li, Yiming Wang, Jian Wang, Shiyin Kang, Xie Chen, Daniel Povey, Sanjeev Khudanpur <br>
<a href="neural-network-language.pdf" target="_blank">Neural Network Language Modeling with Letter-based Features and Importance Sampling</a><br>
(<b>ICASSP 2018</b>)
</li>
<br>

<li><b>Hainan Xu</b>, Guoguo Chen, Daniel Povey and Sanjeev Khudanpur. <br>
<a href="http://www.danielpovey.com/files/2015_interspeech_multitree.pdf" target="_blank">Modeling Phonetic Contexts with Non-random Forests for Speech Recognition</a><br>
(<b>Interspeech 2015</b>) <br>
<a href="hainan_multitree_talk.pdf" target="_blank">Super easy-to-follow slides</a>
<a href="hainan_multitree_poster.pdf" target="_blank">Conference Poster</a>
</li>
<br>

<li><b>Hainan Xu</b>, Philipp Koehn. <br>
<a href="https://pdfs.semanticscholar.org/4c54/d0000851c7dcc6fd414b571624d7aa551598.pdf?_ga=2.54569835.1921197271.1521321380-1455928852.1521321380" target="_blank">Zipporah, an Automatic Data-cleaning System for Noisy Web-crawled Parallel Corpora</a><br>
(<b>EMNLP 2017</b>)
</li>
<br>

<li>Huda Khayrallah, <b>Hainan Xu</b>, Philipp Koehn. <br>
<a href="http://aclweb.org/anthology/W18-6479.pdf" target="_blank">The JHU Parallel Corpus Filtering Systems for WMT 2018</a><br>
(<b>WMT workshop of EMNLP 2018</b>)
</li>
<br>

<li>Yiming Wang, David Snyder, <b>Hainan Xu</b>, Vimal Manohar, Phani Sankar Nidadavolu, Daniel Povey, Sanjeev Khudanpur<br>
<a href="The_JHU_ASR_System_for_VOiCES_from_a_Distance_Challenge_2019.pdf" target="_blank">The JHU ASR System for VOiCES from a Distance Challenge 2019</a><br>
(<b>Interspeech 2019</b>)
</li>
<br>

<li><b>Hainan Xu</b>, Yuchen Fan, Kai Yu <br>
<a href="./ICMI2012_xu.pdf" target="_blank">Development of the 2012 SJTU HVR System</a><br>
(<b>14th ACM International Conference on Multimodal Interaction</b>)
</li>
<br>

<li>Guoguo Chen, <b>Hainan Xu</b>, Minhua Wu, Daniel Povey and Sanjeev Khudanpur. <br>
<a href="http://www.danielpovey.com/files/2015_interspeech_silprob.pdf" target="_blank">Pronunciation and Silence Probability Modeling for ASR</a><br>
(<b>Interspeech 2015</b>)
</li>
<br>

<li>Kai Yu, <b>Hainan Xu</b> <br>
<a href="./INTERSPEECH2013_yu.PDF" target="_blank">Cluster Adaptive Training with Factorized Decision Trees for Speech Recognition</a><br>
(<b>Interspeech 2013</b>)
</li>
<br>

<li>Ke Li, <b>Hainan Xu</b>, Yiming Wang, Dan Povey and Sanjeev Khudanpur <br>
<a href="./adaptation.pdf" target="_blank">Recurrent Neural Network Language Model Adaptation for Conversational Speech Recognition</a><br>
(<b>Interspeech 2018</b>)
</li>
<br>

<li>Zhehuai Chen, Justin Luitjens, <b>Hainan Xu</b>, Yiming Wang, Daniel Povey, Sanjeev Khudanpur <br>
<a href="http://danielpovey.com/files/2018_interspeech_gpu_wfst.pdf" target="_blank">A GPU-based WFST Decoder with Exact Lattice Generation</a><br>
(<b>Interspeech 2018 </b>)
</li>
<br>

<li>Yiming Wang, Vijayaditya Peddinti, <b>Hainan Xu</b>, Xiaohui Zhang, Daniel Povey, Sanjeev Khudanpur <br>
<a href="http://www.danielpovey.com/files/2017_interspeech_backstitch.pdf" target="_blank">Backstitch: Counteracting Finite-sample Bias via Negative Steps</a><br>
(<b>Interspeech 2017</b>) <br>
</li>
<br>

<li>Szu-Jui Chen, Aswin Shanmugam Subramanian, <b>Hainan Xu</b>, Shinji Watanabe <br>
<a href="https://arxiv.org/pdf/1803.10109.pdf" target="_blank">Building state-of-the-art distant speech recognition using the CHiME-4
challenge with a setup of speech enhancement baseline</a><br>
(<b>Interspeech 2018 </b>)
</li>
<br>

<li>Daniel Povey, Gaofeng Cheng, Yiming Wang, Ke Li, <b>Hainan Xu</b>, Mahsa Yarmohamadi, Sanjeev Khudanpur <br>
<a href="http://danielpovey.com/files/2018_interspeech_tdnnf.pdf" target="_blank">Semi-Orthogonal Low-Rank Matrix Factorization for Deep Neural Networks</a><br>
(<b>Interspeech 2018 </b>)
</li>
<br>

<li>Jan Trmal, Matthew Wiesner, Vijayaditya Peddinti, Xiaohui Zhang, Pegah Ghahremani, Yiming Wang, Vimal Manohar, <b>Hainan Xu</b>, Daniel Povey, Sanjeev Khudanpur <br>
<a href="https://pdfs.semanticscholar.org/3119/267d581fb65c3866ded0c194cfac76cc349a.pdf" target="_blank">The Kaldi OpenKWS System: Improving Low Resource Keyword Search</a><br>
(<b>Interspeech 2017</b>)
</li>
<br>

</ul>
<br> 

<hr>

<font size="3">
<script language="javascript"> 
document.write("<i>Last updated "+document.lastModified+" by Hainan Xu<I>"); 
</script>
<br>
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=10588721; 
var sc_invisible=0; 
var sc_security="dfa823d5"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="shopify
analytics tool" href="http://statcounter.com/shopify/"
target="_blank"><img class="statcounter"
src="http://c.statcounter.com/10588721/0/dfa823d5/0/"
alt="shopify analytics tool"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
<a href="http://statcounter.com/p10588721/?guest=1">View My
Stats</a>

<br>
